{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "EyNgTHvd2WFk",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aramnani/Capstone-Project-3---Email-Campaign-Effectiveness-Prediction/blob/main/Email_Campaign_Effectiveness_Prediction_Capstone_Project_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    -\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Classification\n",
        "##### **Contribution**    - Individual\n",
        "##### **Name -** Aakash Ramnani"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Email Marketing can be defined as a marketing technique in which businesses stay connected with their customers through emails, making them aware about their new products, updates, important notices related to the products they are using.\n",
        "\n",
        "Most importantly, email marketing allows businesses to build relationships with leads, new customers and past customers. It's a way to communicate directly to the customers in their inbox, at a time that is convenient for them. With the right messaging tone and strategies, emails are one of the most important marketing channels.\n",
        "\n",
        "In this problem statement, we will be trying to create machine learning models that characterize and predict whether the mail is ignored, read or acknowledged by the reader. In addition to this, we will be trying to analyze and find all the features that are important for an email to not get ignored.\n",
        "\n",
        "The main steps of the project are:\n",
        "\n",
        "1. Basic EDA(Exploratory Data Analysis): I have performed basic EDA to understand the data and its characteristics. Also, have used Univariate - BI variate - and Multivarite analysis to Understanding the correlation between variables and to explore distribution and intercation of variables.\n",
        "\n",
        "2. Hypothesis Testing: I have performed hypothesis testing to test the relationship between the variables. Also have used statistical tests such as t-test, ANOVA, f-test to compare the means or proportions of different groups or categories.\n",
        "\n",
        "3. Feature Engineering and Data Preprocessing: To create and select the most relevant and informative features for the model. Have used methods such as correlation analysis and VIF(Variance Inflation Factor) for feature selection.\n",
        "\n",
        "4. ML Model Development and Evaluation: In this project Have developed and evaluated different machine learning Models. I have used logistic regression, KNN Classifier, Decision Tree, Random Forest and XGBoost.\n",
        "\n",
        "5. Model Interpretation and Explanation : Explained the model predictions using feature importance. It helps to analysis the effect of different factors on the output variable."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Provide your GitHub Link here."
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Most of the small to medium business owners are making effective use of Gmail-based Email marketing Strategies for offline targeting of converting their prospective customers into leads so that they stay with them in business. The main objective is to create a machine learning model to characterize the mail and track the mail that is ignored; read; acknowledged by the reader.**"
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -"
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "\n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "\n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "\n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "\n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "plt.rcParams.update({'figure.figsize':(8,5),'figure.dpi':100})\n",
        "\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from collections import Counter\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, roc_auc_score, f1_score, recall_score,roc_curve, classification_report\n",
        "\n",
        "!pip install shap\n",
        "import shap\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "NPUugCZq4Qba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "dataset = pd.read_csv('/content/drive/MyDrive/Almabetter/machine learning/project/Classification/data_email_campaign.csv')"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "dataset.head()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "print(\"No. of Rows in dataset are : \", dataset.shape[0])\n",
        "print(\"No. of Columns in Dataset are : \", dataset.shape[1])"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "dataset.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We have data points of float, integers and object datatype.\n",
        "- There are missing values in Customer_Location, Total_Past_Communications, Total_Links and Total_Images column."
      ],
      "metadata": {
        "id": "jVYbRufQ5Abv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "dataset.duplicated().sum()"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- There are no duplicated values in our dataset."
      ],
      "metadata": {
        "id": "e1e2P6XV5ioU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "dataset.isnull().sum()"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "sns.heatmap(dataset.isnull(), cbar=False)"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- There are 68353 rows and 12 columns in our dataset.\n",
        "- We have data points of float, integers and object datatype.\n",
        "- There are no duplicated values in our dataset.\n",
        "- There are missing values in Customer_Location, Total_Past_Communications, Total_Links and Total_Images column."
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "dataset.columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "dataset.describe(include = 'all')"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our email campaign dataset have 68353 observations and 12 features. Clearly Email_Status is our target variable.\n",
        "\n",
        "Our features:\n",
        "\n",
        "- **Email Id -** It contains the email id's of the customers/individuals\n",
        "- **Email Type -** There are two categories 1 and 2. We can think of them as marketing emails or important updates, notices like emails regarding the business.\n",
        "- **Subject Hotness Score -** It is the email's subject's score on the basis of how good and effective the content is.\n",
        "- **Email Source -** It represents the source of the email like sales and marketing or important admin mails related to the product.\n",
        "- **Email Campaign Type -** The campaign type of the email.\n",
        "- **Total Past Communications -** This column contains the total previous mails from the same source, the number of communications had.\n",
        "- **Customer Location -** Contains demographical data of the customer, the location where the customer resides.\n",
        "- **Time Email sent Category -** It has three categories 1,2 and 3; the time of the day when the email was sent, we can think of it as morning, evening and night time slots.\n",
        "- **Word Count -** The number of words contained in the email.\n",
        "- **Total links -** Number of links in the email.\n",
        "- **Total Images -** Number of images in the email.\n",
        "- **Email Status -** Our target variable which contains whether the mail was ignored, read, acknowledged by the reader."
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "for col in dataset.columns.to_list():\n",
        "  print(f\"Unique values for {col} are : \",dataset[col].unique())"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code to make your dataset analysis ready.\n",
        "df = dataset.copy()"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**EDA (Exploratory Data Analysis)**"
      ],
      "metadata": {
        "id": "F4g9cwht8Ohz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "4P4Gc8es8ZJD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- There are missing values in Customer_Location, Total_Past_Communications, Total_Links and Total_Images. Max number of missing values are in Customer_Location.\n",
        "\n",
        "- There is no way we can guess the Customer_location to impute the null values, so we will se what effect Customer_Location has on Email_Status and then decide whether to impute the missing values or drop the column."
      ],
      "metadata": {
        "id": "j3-SSryF8r1c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's impute the missing values for other columns except for Customer_location\n",
        "# Checking distribution of Total_Past_Communications for missing value imputation\n",
        "sns.distplot(x = df['Total_Past_Communications'])"
      ],
      "metadata": {
        "id": "3YDMdAWS8y1t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As it can be seen that distribution for Total_Past_Communications is almost normal. So it will be right to impute the missing the values with mean."
      ],
      "metadata": {
        "id": "2oo1XqUJ8-1E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Imputing the missing values of Total_Past_Communications with mean.\n",
        "df['Total_Past_Communications'].fillna(df['Total_Past_Communications'].mean(), inplace = True)"
      ],
      "metadata": {
        "id": "jzBOQWjC9A_h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the distribution for Total_Links\n",
        "sns.displot(x = df['Total_Links'], kde = True)"
      ],
      "metadata": {
        "id": "ExTmX7B69Nx4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the distribution for Total_Images\n",
        "sns.displot(x = df['Total_Images'], kde = True)"
      ],
      "metadata": {
        "id": "1AkcSjgM9WJA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- It is clear from the plot that distribution for both Total_Links and Total_Images is right skewed. So it would be right to impute the missing values with mode."
      ],
      "metadata": {
        "id": "vUBA1rNQ9TWm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Imputing the missing values of Total_Links and Total_Images with mode\n",
        "df['Total_Links'].fillna(df['Total_Links'].mode()[0], inplace = True)\n",
        "df['Total_Images'].fillna(df['Total_Images'].mode()[0], inplace = True)"
      ],
      "metadata": {
        "id": "yHe4vfu89gWX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "BqD8HnRT9onU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Univariate Analysis"
      ],
      "metadata": {
        "id": "9g6sgNm49wOX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Univariate analysis of target variable.\n",
        "df['Email_Status'].value_counts()"
      ],
      "metadata": {
        "id": "F-2St6QY95Oa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 0 is for ignored, 1 is for read and 2 is for acknowledged.\n",
        "- Value count for 0 is way more than value count for 1 and 2.\n",
        "- Our target variable is imbalanced and we'll have to treat it with right technique for our model to work correctly."
      ],
      "metadata": {
        "id": "k3iZG41L-C-h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['Word_Count'] = df['Word_Count'].astype('float64')"
      ],
      "metadata": {
        "id": "_jplmhzW-syR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_feature = df.describe(include = 'int64').columns\n",
        "continuous_feature = df.describe(include = 'float64').columns\n",
        "\n",
        "print(\"Categorical Features are : \", categorical_feature)\n",
        "print(\"Continuous Feature are : \", continuous_feature)"
      ],
      "metadata": {
        "id": "3IX31tNR-22p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the value counts for categorical features\n",
        "for col in categorical_feature:\n",
        "  print(df[col].value_counts())"
      ],
      "metadata": {
        "id": "yr7v4ieF_ZmF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Bi-variate analysis"
      ],
      "metadata": {
        "id": "ftTk-YfWBABo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Continuous Variable vs Target Variable"
      ],
      "metadata": {
        "id": "jDxjo5BdKY_8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Email_Status vs Subject_Hotness_score\n",
        "shs_es = df.groupby(['Email_Status'])['Subject_Hotness_Score'].median().sort_values(ascending = False)"
      ],
      "metadata": {
        "id": "KGuN_TuXAZbo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shs_es"
      ],
      "metadata": {
        "id": "fpYALwsUCXSs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Subject Hotness score for read and acknowledged email is lower."
      ],
      "metadata": {
        "id": "qm5jY7vdD6Aw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Email_Status vs Total_Past_Communications\n",
        "tpc_es = df.groupby(['Email_Status'])['Total_Past_Communications'].median().sort_values(ascending = False)\n",
        "tpc_es"
      ],
      "metadata": {
        "id": "51V0B6hoC2Bl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- More number of past communications high chances of the email being read and acknowledge."
      ],
      "metadata": {
        "id": "QDFaFKiEEDym"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Email_Status vs Word_Count\n",
        "wc_es = df.groupby(['Email_Status'])['Word_Count'].median().sort_values(ascending = False)\n",
        "wc_es"
      ],
      "metadata": {
        "id": "QWwM4VL6EPit"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Lengthy Emails are ignored more than read and acknowledged."
      ],
      "metadata": {
        "id": "dEUSEYwCEg56"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Total_Links vs Email_Status\n",
        "tl_es = df.groupby(['Email_Status'])['Total_Links'].median().sort_values(ascending = False)\n",
        "tl_es"
      ],
      "metadata": {
        "id": "ODBQz2QnEr22"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Median values for all three cases (ignored, read, acknowledged) are almost same."
      ],
      "metadata": {
        "id": "J61Ix3-FFE9n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Total_Images vs Email_Status\n",
        "ti_es = df.groupby(['Email_Status'])['Total_Images'].median().sort_values(ascending = False)\n",
        "ti_es"
      ],
      "metadata": {
        "id": "lfjIFT45FpKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Median value for all three cases (ignored, read, acknowledge) is zero. We need to futher analysis for proper insight."
      ],
      "metadata": {
        "id": "DJab_G8tF6UR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Categorical Variable vs target Variable"
      ],
      "metadata": {
        "id": "Me00KRwrGYEX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Email_Type vs Email_Status\n",
        "et_es = df.groupby(['Email_Type'])['Email_Status'].value_counts()\n",
        "et_es"
      ],
      "metadata": {
        "id": "8f4Yz6LDGMuS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Email Type 1 are sent more than Email type 2, However there is no significant difference in the proportion of emails being ignored, read or acknowledged."
      ],
      "metadata": {
        "id": "sCAdfqZKHQZk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Email_Source_Type vs Email_Status\n",
        "est_es = df.groupby(['Email_Source_Type'])['Email_Status'].value_counts()\n",
        "est_es"
      ],
      "metadata": {
        "id": "FQu-cIU4HkPe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- There is no significant difference between ignored, read or acknowledged emails for both the categories of Email Source Type."
      ],
      "metadata": {
        "id": "LTg08qLxHsLL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Email_Campaign_Type vs Email_Status\n",
        "ect_es = df.groupby(['Email_Campaign_Type'])['Email_Status'].value_counts()\n",
        "ect_es"
      ],
      "metadata": {
        "id": "CKP8J6-dIAFR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Very less number of emails are sent with email campaign type 1.\n",
        "- Maximum number of emails are sent with eamil campaign type 2, however proportion of ignored emails for emal campaign type 2 is very high."
      ],
      "metadata": {
        "id": "PNc8gaj_INj_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Time_Email_sent_Category vs Email_Status\n",
        "tes_es = df.groupby(['Time_Email_sent_Category'])['Email_Status'].value_counts()\n",
        "tes_es"
      ],
      "metadata": {
        "id": "9Vqrx9hCIqQj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Maximum number of emails are sent in time slot 2."
      ],
      "metadata": {
        "id": "NYXaYknwI3cT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Customer_Location vs Email_Status\n",
        "cl_es = df.groupby(['Customer_Location'])['Email_Status'].value_counts()\n",
        "cl_es"
      ],
      "metadata": {
        "id": "5PYfuWWZI9FL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Most number of emails are sent to customer location 'G'."
      ],
      "metadata": {
        "id": "jx35KrczJQlS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- There are missing values in Customer_Location, Total_Past_Communications, Total_Links and Total_Images. Max number of missing values are in Customer_Location.\n",
        "\n",
        "- There is no way we can guess the Customer_location to impute the null values, so we will se what effect Customer_Location has on Email_Status and then decide whether to impute the missing values or drop the column.\n",
        "\n",
        "- Distribution for Total_Past_Communications is almost normal. So we imputed the missing values with mean.\n",
        "\n",
        "- Distribution for both Total_Links and Total_Images is right skewed. So we imputed the missing values with mode.\n",
        "\n",
        "- Our target variable is imbalanced and we'll have to treat it with right technique for our model to work correctly.\n",
        "\n",
        "- Subject Hotness score for read and acknowledged email is lower.\n",
        "\n",
        "- More number of past communications high chances of the email being read and acknowledge.\n",
        "\n",
        "- Lengthy Emails are ignored more than read and acknowledged.\n",
        "\n",
        "- Very less number of emails are sent with email campaign type 1.\n",
        "\n",
        "- Maximum number of emails are sent with eamil campaign type 2, however proportion of ignored emails for emal campaign type 2 is very high.\n",
        "\n",
        "- Most number of emails are sent to customer location 'G'."
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def without_hue(ax, feature):\n",
        "    total = len(feature)\n",
        "    for p in ax.patches:\n",
        "        percentage = '{:.1f}%'.format(100 * p.get_height()/total)\n",
        "        x = p.get_x() + p.get_width() / 2 - 0.05\n",
        "        y = p.get_y() + p.get_height()\n",
        "        ax.annotate(percentage, (x, y), size = 12)"
      ],
      "metadata": {
        "id": "5iy7bBj8Vr9G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1 visualization code\n",
        "# Checking target variable\n",
        "plt.figure(figsize = (7,5))\n",
        "ax = sns.countplot(x = df['Email_Status'])\n",
        "plt.xticks(size = 12)\n",
        "plt.xlabel('Email_Status', size = 12)\n",
        "plt.yticks(size = 12)\n",
        "plt.ylabel('count', size = 12)\n",
        "\n",
        "without_hue(ax, df.Email_Status)"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We used the count plot to plot the value counts of the categories in our target variable."
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 80% of all the emails sent are ignored.\n",
        "- 16.1% of all the emails are read.\n",
        "- 3.5% of all the emails are acknowledged."
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "448CDAPjqfQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The above plot tell us our target variable is imbalanced and we need to treat it with right technique before model deployment to get more accurate predictions.\n",
        "- We'll use undersampling/SMOTE to balance the data to avoid the model being bias to ingnored emails."
      ],
      "metadata": {
        "id": "3cspy4FjqxJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 2 visualization code\n",
        "# Checking categorical variables\n",
        "for col in categorical_feature:\n",
        "    counts = df[col].value_counts().sort_index()\n",
        "    fig = plt.figure(figsize=(9, 6))\n",
        "    ax = fig.gca()\n",
        "    counts.plot.bar(ax = ax, color='steelblue')\n",
        "    ax.set_title(col + ' counts')\n",
        "    ax.set_xlabel(col)\n",
        "    ax.set_ylabel(\"Frequency\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We used count plot as the variable are categorical and we need the value count of data points of each category present in the dataset."
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Email Type - 1 are sent more in compare to Email type - 2.\n",
        "There is no significant difference is Email source type - 1 and Email Source type - 2.\n",
        "Most of the emails are sent using campaign type 2 and very less amount of emails are sent using campaign type 1.\n",
        "Time email sent has three slots 1,2 and 3. Most number of emails are sent in Time email sent slot 2. Time email sent Slot 1 and slot 3 have almost similar counts of email."
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "-JiQyfWJYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need futher analysis to see if there is any business impact."
      ],
      "metadata": {
        "id": "BcBbebzrYklV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 3 visualization code\n",
        "# Checking Distribution for continuous variable\n",
        "for i, value in enumerate(continuous_feature):\n",
        " sns.distplot(x=df[value], hist = True)\n",
        " plt.xlabel(value)\n",
        " plt.show()"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We have used distplot to check the distribution of each continuous variable."
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Except for Total_Past_Communications and Word_Count all the other continuous feature i.e. Subject_Hotness_Score, Total_links and Total_Images are rightly skwed, indicating the presence of outliers."
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "RoGjAbkUYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Checking the distribution can help us impute the missing values and also help us check if we are in line with few of the algorithm assumptions."
      ],
      "metadata": {
        "id": "zfJ8IqMcYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 4 visualization code\n",
        "# Subject_Hotness_score vs Email_Status\n",
        "sns.boxplot(x = df['Email_Status'], y = df['Subject_Hotness_Score'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We have used box plot to check the relation between continuous and target variable, which will also show the presence of outliers in the continuous variable with respect to target variable."
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- In the subject hotness score, median of ignored emails was around 1 with a few outliers.\n",
        "- Acknowledged emails has the most outliers."
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "y-Ehk30pYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- It is observed that the Subject_Hotness_Score for read and acknowledged emails is much lower."
      ],
      "metadata": {
        "id": "jLNxxz7MYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 5 visualization code\n",
        "# Total_Past_Communications vs Email_Status\n",
        "sns.boxplot(x = df['Email_Status'], y = df['Total_Past_Communications'])"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We have used box plot to check the relation between continuous and target variable, which will also show the presence of outliers in the continuous variable with respect to target variable."
      ],
      "metadata": {
        "id": "dcxuIMRPYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "GwzvFGzlYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Median of read and acknowledged emails is more than the ignored emails. These shows that propertion of read and acknowledged emails is higher than ignored emails."
      ],
      "metadata": {
        "id": "uyqkiB8YYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "qYpmQ266Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- It is very evident from the plot that more number of previous interactions with customer, more the customer tend to read and acknowledge the mail. It is important to build a good reppo and connection with customer."
      ],
      "metadata": {
        "id": "_WtzZ_hCYuh4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 6 visualization code\n",
        "# Word_Count vs Email_Status\n",
        "sns.boxplot(x = df['Email_Status'], y = df['Word_Count'])"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "bbFf2-_FphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We have used box plot to check the relation between continuous and target variable, which will also show the presence of outliers in the continuous variable with respect to target variable."
      ],
      "metadata": {
        "id": "loh7H2nzphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "_ouA3fa0phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Proportion of ignored emails is higher than read and acknowledge."
      ],
      "metadata": {
        "id": "VECbqPI7phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "Seke61FWphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- E-mails with high number of words are ignored more than read or acknowledged. Lengthy E-mails should be avoided."
      ],
      "metadata": {
        "id": "DW4_bGpfphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 7 visualization code\n",
        "# Total_Links vs Email_Status\n",
        "sns.boxplot(x = df['Email_Status'], y = df['Total_Links'])"
      ],
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t27r6nlMphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We have used box plot to check the relation between continuous and target variable, which will also show the presence of outliers in the continuous variable with respect to target variable."
      ],
      "metadata": {
        "id": "iv6ro40sphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "r2jJGEOYphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Median value in all three cases for total_links are almost same. There are number of outliers for all three cases."
      ],
      "metadata": {
        "id": "Po6ZPi4hphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "b0JNsNcRphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Total Links has no significant effect on whether emails are being ignored, read or acknowledged."
      ],
      "metadata": {
        "id": "xvSq8iUTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 8"
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 8 visualization code\n",
        "# Total_Images vs Email_Status\n",
        "sns.boxplot(x = df['Email_Status'], y = df['Total_Images'])"
      ],
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "jj7wYXLtphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We have used box plot to check the relation between continuous and target variable, which will also show the presence of outliers in the continuous variable with respect to target variable."
      ],
      "metadata": {
        "id": "Ob8u6rCTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "eZrbJ2SmphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Number of outliers for ignored emails for total images is high."
      ],
      "metadata": {
        "id": "mZtgC_hjphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "rFu4xreNphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "High number of outliers in Total_Images suggest that there are more images in ignored emails."
      ],
      "metadata": {
        "id": "ey_0qi68phqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 9"
      ],
      "metadata": {
        "id": "YJ55k-q6phqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 9 visualization code\n",
        "# Email_Type vs Email_Status\n",
        "ax = sns.countplot(x=df['Email_Type'], hue=df['Email_Status'])\n",
        "unique = len([x for x in df['Email_Type'].unique() if x==x])\n",
        "bars = ax.patches\n",
        "for i in range(unique):\n",
        "  catbars=bars[i:][::unique]\n",
        "  #get height\n",
        "  total = sum([x.get_height() for x in catbars])\n",
        "  #print percentage\n",
        "  for bar in catbars:\n",
        "    ax.text(bar.get_x()+bar.get_width()/2., bar.get_height(), f'{bar.get_height()/total:.0%}', ha=\"center\",va=\"bottom\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "B2aS4O1ophqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "gCFgpxoyphqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We have used countplot to get the value counts of each category in the varibale with respect to the target variable."
      ],
      "metadata": {
        "id": "TVxDimi2phqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "OVtJsKN_phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Number of email type 1 sent is more than email type 2."
      ],
      "metadata": {
        "id": "ngGi97qjphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "lssrdh5qphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The proportion of ignored, read and acknowledged in both the email type is almost same."
      ],
      "metadata": {
        "id": "tBpY5ekJphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 10"
      ],
      "metadata": {
        "id": "U2RJ9gkRphqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 10 visualization code\n",
        "# Email_Source_Type vs Email_Status\n",
        "ax = sns.countplot(x=df['Email_Source_Type'], hue=df['Email_Status'])\n",
        "unique = len([x for x in df['Email_Source_Type'].unique() if x==x])\n",
        "bars = ax.patches\n",
        "for i in range(unique):\n",
        "  catbars=bars[i:][::unique]\n",
        "  #get height\n",
        "  total = sum([x.get_height() for x in catbars])\n",
        "  #print percentage\n",
        "  for bar in catbars:\n",
        "    ax.text(bar.get_x()+bar.get_width()/2., bar.get_height(), f'{bar.get_height()/total:.0%}', ha=\"center\",va=\"bottom\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GM7a4YP4phqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "1M8mcRywphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We have used countplot to get the value counts of each category in the varibale with respect to the target variable."
      ],
      "metadata": {
        "id": "8agQvks0phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "tgIPom80phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is no significant difference in Email_Source_Type 1 and Email_Source_Tpye 2."
      ],
      "metadata": {
        "id": "Qp13pnNzphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "JMzcOPDDphqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Proportion for Emails ignored, read and acknowledged is almost same for both type of sorce."
      ],
      "metadata": {
        "id": "R4Ka1PC2phqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 11"
      ],
      "metadata": {
        "id": "x-EpHcCOp1ci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 11 visualization code\n",
        "# Email_Campaign_Type vs Email_Status\n",
        "ax = sns.countplot(x=df['Email_Campaign_Type'], hue=df['Email_Status'])\n",
        "unique = len([x for x in df['Email_Campaign_Type'].unique() if x==x])\n",
        "bars = ax.patches\n",
        "for i in range(unique):\n",
        "  catbars=bars[i:][::unique]\n",
        "  #get height\n",
        "  total = sum([x.get_height() for x in catbars])\n",
        "  #print percentage\n",
        "  for bar in catbars:\n",
        "    ax.text(bar.get_x()+bar.get_width()/2., bar.get_height(), f'{bar.get_height()/total:.0%}', ha=\"center\",va=\"bottom\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mAQTIvtqp1cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "X_VqEhTip1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We have used countplot to get the value counts of each category in the varibale with respect to the target variable."
      ],
      "metadata": {
        "id": "-vsMzt_np1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "8zGJKyg5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Most of the Emails sent are through email campaign type 2. Most ignored emails are also of campaign type 2.\n",
        "- Emails sent through campaign type 1 are very less in number."
      ],
      "metadata": {
        "id": "ZYdMsrqVp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "PVzmfK_Ep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Emails sent through campaign type 1 are very less in number. However the rate at which the emails are read and acknoledged is better than campaign type 2 and campaign type 3.\n",
        "\n",
        "- Campaign type 3 has good results, with less number of emails sent but comparatively more number of emails out of sent emails were read and acknowledged."
      ],
      "metadata": {
        "id": "druuKYZpp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 12"
      ],
      "metadata": {
        "id": "n3dbpmDWp1ck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 12 visualization code\n",
        "# Time_Email_sent_Category vs Email_Status\n",
        "ax = sns.countplot(x=df['Time_Email_sent_Category'], hue=df['Email_Status'])\n",
        "unique = len([x for x in df['Time_Email_sent_Category'].unique() if x==x])\n",
        "bars = ax.patches\n",
        "for i in range(unique):\n",
        "  catbars=bars[i:][::unique]\n",
        "  #get height\n",
        "  total = sum([x.get_height() for x in catbars])\n",
        "  #print percentage\n",
        "  for bar in catbars:\n",
        "    ax.text(bar.get_x()+bar.get_width()/2., bar.get_height(), f'{bar.get_height()/total:.0%}', ha=\"center\",va=\"bottom\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bwevp1tKp1ck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "ylSl6qgtp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We have used countplot to get the value counts of each category in the varibale with respect to the target variable."
      ],
      "metadata": {
        "id": "m2xqNkiQp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ZWILFDl5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Time_Email_sent_Category is divided into 3 slots.\n",
        "- Most number of emails are sent in time slot 2."
      ],
      "metadata": {
        "id": "x-lUsV2mp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "M7G43BXep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The proportion of ignored, read and acknowledged emails is almost same for all three time slots."
      ],
      "metadata": {
        "id": "5wwDJXsLp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 13"
      ],
      "metadata": {
        "id": "Ag9LCva-p1cl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 13 visualization code\n",
        "# Customer_Location vs Email_Status\n",
        "ax = sns.countplot(x=df['Customer_Location'], hue=df['Email_Status'])\n",
        "unique = len([x for x in df['Customer_Location'].unique() if x==x])\n",
        "bars = ax.patches\n",
        "for i in range(unique):\n",
        "  catbars=bars[i:][::unique]\n",
        "  #get height\n",
        "  total = sum([x.get_height() for x in catbars])\n",
        "  #print percentage\n",
        "  for bar in catbars:\n",
        "    ax.text(bar.get_x()+bar.get_width()/2., bar.get_height(), f'{bar.get_height()/total:.0%}', ha=\"center\",va=\"bottom\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EUfxeq9-p1cl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "E6MkPsBcp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We have used countplot to get the value counts of each category in the varibale with respect to the target variable."
      ],
      "metadata": {
        "id": "V22bRsFWp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "2cELzS2fp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Most number of emails are sent to location 'G'."
      ],
      "metadata": {
        "id": "ozQPc2_Ip1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "3MPXvC8up1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Proportion of ignored, read and acknowledged emails for Customer_Location is almost same for all the location. Indicating that Customer_Location has no significant effect on the output variable.\n",
        "- Thus we can drop the column Customer_Location which has highest number of missing values."
      ],
      "metadata": {
        "id": "GL8l1tdLp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 14 - Correlation Heatmap"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Heatmap visualization code\n",
        "plt.figure(figsize=(15,8))\n",
        "correlation = df.corr()\n",
        "sns.heatmap(abs(correlation), annot=True, cmap='coolwarm')"
      ],
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "UV0SzAkaZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We have used correlation heatmap to check the multicolinearity and correlation between variables."
      ],
      "metadata": {
        "id": "DVPuT8LYZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "YPEH6qLeZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Email Campaign Type and Total past communication shows positive correlation with emails being read and acknowledged.\n",
        "- Total_Links and Total_Images show high corelation."
      ],
      "metadata": {
        "id": "bfSqtnDqZNRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 15 - Pair Plot"
      ],
      "metadata": {
        "id": "q29F0dvdveiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pair Plot visualization code\n",
        "\n",
        "plt.figure(figsize=(15,15))\n",
        "# setting the axis for graph\n",
        "sns.pairplot(df)\n",
        "# adding visualizations to chart\n",
        "plt.minorticks_on()\n",
        "plt.grid(which='both',alpha=0.3,linestyle='--')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "o58-TEIhveiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "EXh0U9oCveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have used pairplot to understand the best set of features to explain the relationship between two variables."
      ],
      "metadata": {
        "id": "eMmPjTByveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "22aHeOlLveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Total_Images and Total_Links are highly corelated. So we can either select any one of the feature or combine both to form one feature for model implementation."
      ],
      "metadata": {
        "id": "uPQ8RGwHveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. Hypothesis Testing***"
      ],
      "metadata": {
        "id": "g-ATYxFrGrvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."
      ],
      "metadata": {
        "id": "Yfr_Vlr8HBkt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Hypothesis - 1 -** The proportion of ignored, read and acknowledged emails is almost same for all the customer location.\n",
        "- **Hypothesis - 2 -** There is no correlation between Total_Links and Total_Images.\n",
        "- **Hypothesis - 3 -** Total_Past_Communication has no effect on Email_Status."
      ],
      "metadata": {
        "id": "-7MS06SUHkB-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 1"
      ],
      "metadata": {
        "id": "8yEUt7NnHlrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "tEA2Xm5dHt1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Null Hypothesis (H0) -** The proportion of ingmored, read and acknowledge emails is almost same for all the customer locations.\n",
        "- **Alternate Hypothesis (HA) -** Their is a huge difference in proportion of ignored, read and acknowledged emails for all the customer location.\n",
        "\n",
        "\n",
        "- As we have two categorical features to compare we will use chi-square test with significance level 0.05 for these hypothesis."
      ],
      "metadata": {
        "id": "HI9ZP0laH0D-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "I79__PHVH19G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install researchpy\n",
        "import researchpy as rp\n",
        "import scipy.stats as stats"
      ],
      "metadata": {
        "id": "srjpd9lkZ2Of"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "# Chi-Square Test\n",
        "crosstab, test_results, expected = rp.crosstab(dataset[\"Customer_Location\"], dataset[\"Email_Status\"],\n",
        "                                               test= \"chi-square\",\n",
        "                                               expected_freqs= True,\n",
        "                                               prop= \"cell\")"
      ],
      "metadata": {
        "id": "oZrfquKtyian"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "crosstab"
      ],
      "metadata": {
        "id": "fUVBbiUbb-xk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_results"
      ],
      "metadata": {
        "id": "oBUZdv8IcB9S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- As p value 0.5240 is greater than significance level 0.05, we cannot reject the null hypothesis."
      ],
      "metadata": {
        "id": "P6Ck21_ZxHP_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "Ou-I18pAyIpj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We have used chi-square test to obtain the p-value."
      ],
      "metadata": {
        "id": "s2U0kk00ygSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "fF3858GYyt-u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- As both of our variable for the test are categorical we have used chi-square test."
      ],
      "metadata": {
        "id": "HO4K0gP5y3B4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 2"
      ],
      "metadata": {
        "id": "4_0_7-oCpUZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "hwyV_J3ipUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Null Hypothesis (H0) -** There is no correlation between Total_Links and Total_Images.\n",
        "- **Alternate Hypothesis (HA) -** Total_Links and Total_Images are highly correlated.\n",
        "\n",
        "- As we have two quantitative variables and we need to find the correlation we will be using pearson correlation test."
      ],
      "metadata": {
        "id": "FnpLGJ-4pUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "3yB-zSqbpUZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "# Pearson's Correlation Test\n",
        "from scipy.stats.stats import pearsonr"
      ],
      "metadata": {
        "id": "sWxdNTXNpUZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "var1 = dataset['Total_Links'].fillna(dataset['Total_Links'].mode()[0])\n",
        "var2 = dataset['Total_Images'].fillna(dataset['Total_Images'].mode()[0])"
      ],
      "metadata": {
        "id": "DSkQRUYT6LEh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pearsonr(var1, var2)"
      ],
      "metadata": {
        "id": "Ida-zRZW6OWL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Value for r (correlation coefficient) is 0.75 which is greater than 0.5 which indicates a high correlation between two variable.\n",
        "- Value of p is 0 which less than significance level 0.05, so we will reject the null hypothesis."
      ],
      "metadata": {
        "id": "XBnTPwWF7C3p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "dEUvejAfpUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We have used pearson's correlation test to test the given hypothesis."
      ],
      "metadata": {
        "id": "oLDrPz7HpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "Fd15vwWVpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We have used pearson's correlation test as we need to find the correlation between two continuous variable not following a normal distribution."
      ],
      "metadata": {
        "id": "4xOGYyiBpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 3"
      ],
      "metadata": {
        "id": "bn_IUdTipZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "49K5P_iCpZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Null Hypothesis (H0) -** Total_Past_Communication has no significant effect on Email_Status.\n",
        "- **Alternate Hypothesis (HA) -** Total_Past_Communication has significant effect on Email_Status.\n",
        "\n",
        "- We need to test for one categorical variable and one quantitative variable we will use one anova test with significance level 0.05."
      ],
      "metadata": {
        "id": "7gWI5rT9pZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "Nff-vKELpZyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "var1 = dataset['Total_Past_Communications'].fillna(dataset['Total_Past_Communications'].mean())\n",
        "var2 = dataset['Email_Status']"
      ],
      "metadata": {
        "id": "s6AnJQjtpZyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "# One Way ANOVA test\n",
        "from scipy.stats import f_oneway\n",
        "f_oneway(var1, var2)"
      ],
      "metadata": {
        "id": "e-H3b67mBR_I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Here p-value 0.00 is less than significance value 0.05, so we will reject the null hypothesis."
      ],
      "metadata": {
        "id": "wASZXub7BvHc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "kLW572S8pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We have used one way ANOVA test to obtain p-value."
      ],
      "metadata": {
        "id": "ytWJ8v15pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "dWbDXHzopZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We have one categorical variable and one quantitative variable to compare so we used one way ANOVA test to test the given hypothesis."
      ],
      "metadata": {
        "id": "M99G98V6pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Missing Values & Missing Value Imputation\n",
        "dataset.isnull().sum()"
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- There were missing values in Customer_Location, Total_Past_Communications, Total_Links and Total_Images.\n",
        "- We imputed the missing values in Total_Past_Cummunications by mean as its distribution was almost normal.\n",
        "- We imputed missing values is Total_Links and Total_Images by mode. Their distribution was right skewed.\n",
        "- As there is no way we can guess the customer location so we checked whether or not there is a significant impact of Customer_Location on out target variable. And we found that there is no effect of Customer_Location on our target variable so we will drop the Customer_Location column."
      ],
      "metadata": {
        "id": "AvcLSRWHrbHV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropping Customer_Location\n",
        "df.drop('Customer_Location', axis = 1, inplace = True)"
      ],
      "metadata": {
        "id": "luPepmluq9UZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "7OUGNQvhrVN-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all missing value imputation techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "7wuGOrhz0itI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- There were missing values in Customer_Location, Total_Past_Communications, Total_Links and Total_Images.\n",
        "- We imputed the missing values in Total_Past_Cummunications by mean as its distribution was almost normal.\n",
        "- We imputed missing values is Total_Links and Total_Images by mode. Their distribution was right skewed.\n",
        "- As there is no way we can guess the customer location so we checked whether or not there is a significant impact of Customer_Location on out target variable. And we found that there is no effect of Customer_Location on our target variable so we will drop the Customer_Location column."
      ],
      "metadata": {
        "id": "1ixusLtI0pqI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Feature Manipulation & Selection"
      ],
      "metadata": {
        "id": "-oLEiFgy-5Pf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Feature Manipulation"
      ],
      "metadata": {
        "id": "C74aWNz2AliB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Manipulate Features to minimize feature correlation and create new features\n",
        "# Plotting correlation for refrence\n",
        "plt.figure(figsize=(15,8))\n",
        "correlation = df.corr()\n",
        "sns.heatmap(abs(correlation), annot=True, cmap='coolwarm')"
      ],
      "metadata": {
        "id": "h1qC4yhBApWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# VIF for checking multicolinearity\n",
        "def calc_vif(X):\n",
        "\n",
        "    # Calculating VIF\n",
        "    vif = pd.DataFrame()\n",
        "    vif[\"variables\"] = X.columns\n",
        "    vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
        "\n",
        "    return(vif)"
      ],
      "metadata": {
        "id": "z1ITyebgtC0D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calc_vif(df[[i for i in df.describe().columns if i not in categorical_feature]])"
      ],
      "metadata": {
        "id": "vnEMXxI_tIoF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Total_Links and Total_Images are highly Correlated so combining them to create a new column Total_Links_Images, and dropping Total_Images and Total_Links from data frame."
      ],
      "metadata": {
        "id": "zl9uqE5xtStE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Total_Links and Total_Images are highly correlated so combining both the column into new column\n",
        "df['Total_links_images'] = df['Total_Images'] + df['Total_Links']\n",
        "df.drop(['Total_Images','Total_Links'], axis = 1, inplace = True)"
      ],
      "metadata": {
        "id": "LoUIEktDtlF4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calc_vif(df[[i for i in df.describe().columns if i not in categorical_feature]])"
      ],
      "metadata": {
        "id": "5_rt5Zn6toZ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We have multicolinearity checked."
      ],
      "metadata": {
        "id": "wHKFC0rztr0w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Feature Selection"
      ],
      "metadata": {
        "id": "2DejudWSA-a0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select your features wisely to avoid overfitting\n",
        "# We do not need Email_ID for prediction so dropping Email_ID from dataframe.\n",
        "df.drop('Email_ID', axis =1, inplace = True)"
      ],
      "metadata": {
        "id": "YLhe8UmaBCEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all feature selection methods have you used  and why?"
      ],
      "metadata": {
        "id": "pEMng2IbBLp7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We used correlation and Variance Inflation Factor to check the multicolinearity and we combined Total_Images and Total_Links to Total_links_images and dropped Total_Images and Total_Links.\n",
        "- We dropped Email_ID and Customer_Location as they have no impact on target variable."
      ],
      "metadata": {
        "id": "rb2Lh6Z8BgGs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which all features you found important and why?"
      ],
      "metadata": {
        "id": "rAdphbQ9Bhjc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "KklhuuKOvX0N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "fGgaEstsBnaf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Handling Outliers"
      ],
      "metadata": {
        "id": "id1riN9m0vUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "continuous_feature = df.describe(include = 'float64').columns"
      ],
      "metadata": {
        "id": "RXpLOaIev7Db"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "continuous_features = continuous_feature.drop('Word_Count')"
      ],
      "metadata": {
        "id": "QD8ry_cKwEzj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Outliers & Outlier treatments\n",
        "# Number of Outliers in all the continuous features\n",
        "outliers = {}\n",
        "for col in continuous_features:\n",
        "  q_75, q_25 = np.percentile(df.loc[:,col],[75,25])\n",
        "  IQR = q_75-q_25\n",
        "  max = q_75+(1.5*IQR)\n",
        "  min = q_25-(1.5*IQR)\n",
        "  outlier_list=[]\n",
        "  outlier_list=df.loc[df[col] < min]['Email_Status'].tolist()\n",
        "  outlier_list.append(df.loc[df[col] > max]['Email_Status'].tolist())\n",
        "  outliers[col]={}\n",
        "  for i in outlier_list[0]:\n",
        "      outliers[col][i] = outliers[col].get(i,0) + 1\n",
        "print(outliers)"
      ],
      "metadata": {
        "id": "M6w2CzZf04JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We have the number of outliers with respect to Email_Status.\n",
        "- Our output data is imbalanced, Email_Status value 1 and value 2 are in minority class.\n",
        "- For our model to predict coreclty and not be biased to one class, we need to take care that we are not deleting more than 5% of useful data related to minority class."
      ],
      "metadata": {
        "id": "QepwJfUowT64"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Percentage of outliers in minority class\n",
        "min_outliers = 0\n",
        "maj_outliers = 0\n",
        "for col in continuous_features:\n",
        "  min_outliers += outliers[col][1]\n",
        "  min_outliers += outliers[col][2]\n",
        "  maj_outliers += outliers[col][0]\n",
        "\n",
        "total_min = df['Email_Status'].value_counts()[1] + df['Email_Status'].value_counts()[2]\n",
        "total_maj = df['Email_Status'].value_counts()[0]\n",
        "\n",
        "min_outliers_per = (min_outliers/total_min)*100\n",
        "maj_outliers_per = (maj_outliers/total_maj)*100\n",
        "total_percentage = ((min_outliers+maj_outliers)/(total_min+total_maj))*100\n",
        "print(f'The percentage of outliers in minority classes is {min_outliers_per}')\n",
        "print(f'The percentage of outliers in majority class is {maj_outliers_per}')\n",
        "print(f'The percentage of total outliers are {total_percentage}')"
      ],
      "metadata": {
        "id": "bQvFivEVwcAu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- There are more than 5% outliers for minority class so we will not be deleting them.\n",
        "- Deleting the outliers for majority class."
      ],
      "metadata": {
        "id": "hiMedtl_wr9o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Deleting outliers for majority class\n",
        "for col in continuous_features:\n",
        "  q_low = df[col].quantile(0.01)\n",
        "  q_hi  = df[col].quantile(0.99)\n",
        "  df = df.drop(df[(df[col] > q_hi) &  (df['Email_Status']==0)].index)\n",
        "  df = df.drop(df[(df[col] < q_low) & (df['Email_Status']==0)].index)"
      ],
      "metadata": {
        "id": "0MWQdYfpww3q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all outlier treatment techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "578E2V7j08f6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We have the number of outliers with respect to Email_Status.\n",
        "- Our output data is imbalanced, Email_Status value 1 and value 2 are in minority class.\n",
        "- For our model to predict coreclty and not be biased to one class, we need to take care that we are not deleting more than 5% of useful data related to minority class.\n",
        "- There are more than 5% outliers for minority class so we will not be deleting them.\n",
        "- Deleted the outliers for majority class."
      ],
      "metadata": {
        "id": "uGZz5OrT1HH-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Categorical Encoding"
      ],
      "metadata": {
        "id": "89xtkJwZ18nB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the target variable from dataframe.\n",
        "x1 = df.drop('Email_Status', axis =1)\n",
        "y1 = df['Email_Status']"
      ],
      "metadata": {
        "id": "DQkK_M7exO28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x1.shape)\n",
        "print(y1.shape)"
      ],
      "metadata": {
        "id": "nNtQcu81xc5q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_feature"
      ],
      "metadata": {
        "id": "AAT22gBExobO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_features = categorical_feature.drop('Email_Status')\n",
        "categorical_features"
      ],
      "metadata": {
        "id": "QSaCbR9mxrnI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode your categorical columns\n",
        "# OneHot Encoding for categorical features\n",
        "x_ohe = pd.get_dummies(x1, columns = categorical_features, drop_first = True)\n",
        "x_ohe.head()"
      ],
      "metadata": {
        "id": "21JmIYMG2hEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all categorical encoding techniques have you used & why did you use those techniques?"
      ],
      "metadata": {
        "id": "67NQN5KX2AMe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We have used one hot encoding as the categorical data was nominal and not ordinal."
      ],
      "metadata": {
        "id": "UDaue5h32n_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Data Scaling"
      ],
      "metadata": {
        "id": "rMDnDkt2B6du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling your data\n",
        "scaler = StandardScaler()\n",
        "x_scaled = scaler.fit_transform(x_ohe)"
      ],
      "metadata": {
        "id": "dL9LWpySC6x_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_scaled_df = pd.DataFrame(x_scaled, columns = x_ohe.columns)\n",
        "x_scaled_df.head()"
      ],
      "metadata": {
        "id": "sEE28QhcyixS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which method have you used to scale you data and why?"
      ],
      "metadata": {
        "id": "yiiVWRdJDDil"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- A standard scaler is a data preprocessing technique that transforms the numerical features of a dataset to have a mean of zero and a standard deviation of one, which can improve the performance of model.\n",
        "\n",
        "- It scales the features to a common range, which can help compare different features and avoid dominance of some features over others due to their large magnitude."
      ],
      "metadata": {
        "id": "jQRU9OVmytF9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Handling Imbalanced Dataset"
      ],
      "metadata": {
        "id": "P1XJ9OREExlT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think the dataset is imbalanced? Explain Why."
      ],
      "metadata": {
        "id": "VFOzZv6IFROw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 80% of all the emails sent are ignored.\n",
        "- 16.1% of all the emails are read.\n",
        "- 3.5% of all the emails are acknowledged.\n",
        "\n",
        "It is clear that our output variable is imbalanced. Email_Status value 1 and value 2 are the miority class. We need to treat it with proper technique before model implementation for more accurate predictions."
      ],
      "metadata": {
        "id": "GeKDIv7pFgcC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Imbalanced Dataset (If needed)\n",
        "# SMOTE (Synthetic Minority Oversampling Technique)\n",
        "smote = SMOTE()\n",
        "\n",
        "x_smote,y_smote = smote.fit_resample(x_scaled,y1)"
      ],
      "metadata": {
        "id": "nQsRhhZLFiDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"x before SMOTE : \", x_scaled.shape)\n",
        "print(\"x after SMOTE : \", x_smote.shape)\n",
        "print(\"y before SMOTE : \", y1.shape)\n",
        "print(\"y after SMOTE : \", y_smote.shape)"
      ],
      "metadata": {
        "id": "2e7cXMl31FAd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visulizing data before SMOTE\n",
        "plt.bar(Counter(df['Email_Status']).keys(), Counter(df['Email_Status']).values())\n",
        "plt.title(\"Before SMOTE\")"
      ],
      "metadata": {
        "id": "OyXX9M561mL4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visulizing data after SMOTE\n",
        "plt.bar(Counter(y_smote).keys(), Counter(y_smote).values())\n",
        "plt.title(\"After SMOTE\")"
      ],
      "metadata": {
        "id": "IrseMqvO1v1i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_values, count_values = np.unique(y_smote, return_counts=True)\n",
        "print(\"Frequency of unique values of the Email_Status:\")\n",
        "print(np.asarray((unique_values, count_values)))"
      ],
      "metadata": {
        "id": "ZUIXQ9rv2QpA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We have balanced data with 53502 data points for each class."
      ],
      "metadata": {
        "id": "62114wUT2ShP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What technique did you use to handle the imbalance dataset and why? (If needed to be balanced)"
      ],
      "metadata": {
        "id": "TIqpNgepFxVj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We have used SMOTE technique to treat imbalanced data.\n",
        "- SMOTE generates synthetic data for minority class.\n",
        "- SMOTE (Synthetic Minority Oversampling Technique) works by randomly picking a point from the minority class and computing the k-nearest neighbors for this point. The synthetic points are added between the chosen point and its neighbors.\n",
        "- SMOTE will save us from the problem of loss of information unlike other techniques like under sampling."
      ],
      "metadata": {
        "id": "qbet1HwdGDTz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Data Splitting"
      ],
      "metadata": {
        "id": "BhH2vgX9EjGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split your data to train and test. Choose Splitting ratio wisely.\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_smote, y_smote, test_size = 0.2, random_state = 42, stratify = y_smote)"
      ],
      "metadata": {
        "id": "0CTyd2UwEyNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Shape of x_train : \", x_train.shape)\n",
        "print(\"Shape of x_test : \", x_test.shape)\n",
        "print(\"Shape of y_train : \", y_train.shape)\n",
        "print(\"Shape of y_test : \", y_test.shape)"
      ],
      "metadata": {
        "id": "OVgjgUYP2j0c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What data splitting ratio have you used and why?"
      ],
      "metadata": {
        "id": "qjKvONjwE8ra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- As our dataset is small we have used 80% - 20% splitting ratio i.e. 80% of data is training set and 20% is test set.\n",
        "- We need to use the stratify parameter inorder to make sure that the train and test datasets have the same ratios of the predictor variables."
      ],
      "metadata": {
        "id": "Y2lJ8cobFDb_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Function for evaluating models."
      ],
      "metadata": {
        "id": "rmMaxR--3qYq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Columns for comparison matrics\n",
        "comparison_columns = ['Model_Name', 'Train_Accuracy', 'Train_Recall', 'Train_Precision', 'Train_F1score', 'Train_AUC' ,'Test_Accuracy', 'Test_Recall', 'Test_Precision', 'Test_F1score', 'Test_AUC']"
      ],
      "metadata": {
        "id": "wpQEMTBg3nw9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to evaluate the model\n",
        "def model_evaluation(model_name, model_var, x_train, y_train, x_test, y_test):\n",
        "  ''' This function predicts and evaluates various models for clasification algorithms, visualizes results\n",
        "      and creates a dataframe that compares the various models.'''\n",
        "\n",
        "  #Making predictions\n",
        "  y_pred_train = model_var.predict(x_train)\n",
        "  y_pred_test = model_var.predict(x_test)\n",
        "\n",
        "  #probs\n",
        "  train_prob = model_var.predict_proba(x_train)\n",
        "  test_prob = model_var.predict_proba(x_test)\n",
        "\n",
        "  #Accuracy\n",
        "  accuracy_train = accuracy_score(y_train,y_pred_train)\n",
        "  accuracy_test = accuracy_score(y_test,y_pred_test)\n",
        "\n",
        "  #Confusion Matrix\n",
        "  cm_train = confusion_matrix(y_train,y_pred_train)\n",
        "  cm_test = confusion_matrix(y_test,y_pred_test)\n",
        "\n",
        "  #Recall\n",
        "  train_recall = recall_score(y_train,y_pred_train, average='weighted')\n",
        "  test_recall = recall_score(y_test,y_pred_test, average='weighted')\n",
        "\n",
        "  #Precision SMOTE\n",
        "  train_precision = precision_score(y_train,y_pred_train, average='weighted')\n",
        "  test_precision = precision_score(y_test,y_pred_test, average='weighted')\n",
        "\n",
        "  #F1 Score\n",
        "  train_f1 = f1_score(y_train,y_pred_train, average='weighted')\n",
        "  test_f1 = f1_score(y_test,y_pred_test, average='weighted')\n",
        "\n",
        "  #ROC-AUC\n",
        "  train_auc = roc_auc_score(y_train,train_prob,average='weighted',multi_class = 'ovr')\n",
        "  test_auc = roc_auc_score(y_test,test_prob,average='weighted',multi_class = 'ovr')\n",
        "\n",
        "  #Visualising Results\n",
        "  print(\"----- Evaluation -------\" + str(model_name) + '-----')\n",
        "  print(\"---------------Test data ---------------\\n\")\n",
        "  print(\"Confusion matrix \\n\")\n",
        "  print(cm_test)\n",
        "  print(classification_report(y_test,y_pred_test))\n",
        "\n",
        "  #create ROC curve\n",
        "  fpr = {}\n",
        "  tpr = {}\n",
        "  thresh ={}\n",
        "  no_of_class=3\n",
        "  for i in range(no_of_class):\n",
        "      fpr[i], tpr[i], thresh[i] = metrics.roc_curve(y_test, test_prob[:,i], pos_label=i)\n",
        "  plt.plot(fpr[0], tpr[0], linestyle='--',color='blue', label='Class 0 vs Others'+\" AUC=\"+str(test_auc))\n",
        "  plt.plot(fpr[1], tpr[1], linestyle='--',color='green', label='Class 1 vs Others'+\" AUC=\"+str(test_auc))\n",
        "  plt.plot(fpr[2], tpr[2], linestyle='--',color='orange', label='Class 2 vs Others'+\" AUC=\"+str(test_auc))\n",
        "  plt.title('Multiclass ROC curve of '+ str(model_name))\n",
        "  plt.ylabel('True Positive Rate')\n",
        "  plt.xlabel('False Positive Rate')\n",
        "  plt.legend(loc=4)\n",
        "  plt.show()\n",
        "\n",
        "  #Saving our results\n",
        "  global comparison_columns\n",
        "\n",
        "  metric_scores = [model_name,accuracy_train,train_recall,train_precision,train_f1,train_auc,accuracy_test,test_recall,test_precision,test_f1,test_auc]\n",
        "  final_dict = dict(zip(comparison_columns,metric_scores))\n",
        "  dict_list = [final_dict]\n",
        "\n",
        "  return dict_list"
      ],
      "metadata": {
        "id": "vrYmgxFa35rT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#function to create the comparison table\n",
        "final_list = []\n",
        "def add_dict_to_final_df(final_dict):\n",
        "  global final_list\n",
        "  for elem in final_dict:\n",
        "    final_list.append(elem)\n",
        "  global comp_df\n",
        "  comp_df = pd.DataFrame(final_list, columns= comparison_columns)"
      ],
      "metadata": {
        "id": "zhlWUfD_5A9d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1 - Logistic Regression"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation\n",
        "lor = LogisticRegression(class_weight='balanced',multi_class='multinomial', solver='lbfgs')\n",
        "\n",
        "# Fit the Algorithm\n",
        "lor.fit(x_train,y_train)"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "logistic_reg_eval = model_evaluation('Logistic Regression', lor, x_train, y_train, x_test, y_test)\n",
        "logistic_reg_eval"
      ],
      "metadata": {
        "id": "rqD5ZohzfxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#adding result to final list\n",
        "add_dict_to_final_df(logistic_reg_eval)\n",
        "comp_df"
      ],
      "metadata": {
        "id": "Cd3bl3iP5jqm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2 - Decision Tree"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation\n",
        "dtc = DecisionTreeClassifier()\n",
        "\n",
        "# Fit the Algorithm\n",
        "dtc.fit(x_train, y_train)"
      ],
      "metadata": {
        "id": "7MEuYkqf57mQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "JWYfwnehpsJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "decision_tree_eval = model_evaluation('Decision Tree', dtc, x_train, y_train, x_test, y_test)\n",
        "decision_tree_eval"
      ],
      "metadata": {
        "id": "yEl-hgQWpsJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#adding result to final list\n",
        "add_dict_to_final_df(decision_tree_eval)\n",
        "comp_df"
      ],
      "metadata": {
        "id": "6vjVq42n6M25"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 3 - Random Forest"
      ],
      "metadata": {
        "id": "Fze-IPXLpx6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation\n",
        "rfc = RandomForestClassifier(random_state=42, max_depth=5, n_estimators=100, oob_score=True)\n",
        "\n",
        "# Fit the Algorithm\n",
        "rfc.fit(x_train, y_train)"
      ],
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "7AN1z2sKpx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "random_forest_eval = model_evaluation('Random Forest', rfc, x_train, y_train, x_test, y_test)\n",
        "random_forest_eval"
      ],
      "metadata": {
        "id": "xIY4lxxGpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#adding result to final list\n",
        "add_dict_to_final_df(random_forest_eval)\n",
        "comp_df"
      ],
      "metadata": {
        "id": "IznAp2rH7Egc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "9PIHJqyupx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "rfc_gd = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
        "\n",
        "#GridSearchCV\n",
        "params = {'max_depth': [3,5,10,20],'min_samples_leaf': [5,10,20,50,100],'n_estimators': [10,25,30,50,100,200]}\n",
        "gd_cv = GridSearchCV(estimator=rfc_gd, param_grid=params, cv = 4, n_jobs=-1, verbose=1, scoring=\"f1_weighted\")\n",
        "\n",
        "# Fit the Algorithm\n",
        "gd_cv.fit(x_train, y_train)"
      ],
      "metadata": {
        "id": "eSVXuaSKpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf_gd_bp = gd_cv.best_estimator_\n",
        "rf_gd_bp"
      ],
      "metadata": {
        "id": "RSr4FOtGIDNs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_forest_tunned_eval = model_evaluation('Random Forest tunned', rf_gd_bp, x_train, y_train, x_test, y_test)\n",
        "random_forest_tunned_eval"
      ],
      "metadata": {
        "id": "h2SQha5qIHBk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#adding result to final list\n",
        "add_dict_to_final_df(random_forest_tunned_eval)\n",
        "comp_df"
      ],
      "metadata": {
        "id": "nrMg388EIQsz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "_-qAgymDpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We have used GridSearchCV for hyperparameter tuning.\n",
        "- GridSearchCV tries all the combinations of the values passed in the dictionary and evaluates the model for each combination using the Cross-Validation method.\n",
        "- Hence after using this function we get accuracy/loss for every combination of hyperparameters and we can choose the one with the best performance"
      ],
      "metadata": {
        "id": "lQMffxkwpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 4 - KNN Classifier"
      ],
      "metadata": {
        "id": "AEAsC8Y2OTuP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 4 Implementation\n",
        "knn_clf = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n",
        "\n",
        "# Fit the Algorithm\n",
        "knn_clf.fit(x_train, y_train)"
      ],
      "metadata": {
        "id": "aP_dm_NxOga7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "YcEltuVfOyd3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "knn_classifier_eval = model_evaluation('KNN Classifier', knn_clf, x_train, y_train, x_test, y_test)\n",
        "knn_classifier_eval"
      ],
      "metadata": {
        "id": "a4XXeAgKO2CT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#adding result to final list\n",
        "add_dict_to_final_df(knn_classifier_eval)\n",
        "comp_df"
      ],
      "metadata": {
        "id": "hVPGPV7aPLY9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "SnJHLDNbOz8i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameter Grid\n",
        "params_knn = {'n_neighbors':np.arange(1,5)}\n",
        "\n",
        "# ML Model - 4 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "knn = KNeighborsClassifier()\n",
        "knn_rd_cv= RandomizedSearchCV(knn,params_knn,cv=5)\n",
        "\n",
        "# Fit the Algorithm\n",
        "knn_rd_cv.fit(x_train,y_train)"
      ],
      "metadata": {
        "id": "EYk0TA_0PeJY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Best Parameters\n",
        "knn_rd_cv_bp = knn_rd_cv.best_params_\n",
        "knn_rd_cv_bp"
      ],
      "metadata": {
        "id": "p9V-ewrvTF2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "knn_classifier_tunned_eval = model_evaluation('KNN Classifier tunned', knn_rd_cv, x_train, y_train, x_test, y_test)\n",
        "knn_classifier_tunned_eval"
      ],
      "metadata": {
        "id": "tPF4l0A_Ta9F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#adding result to final list\n",
        "add_dict_to_final_df(knn_classifier_tunned_eval)\n",
        "comp_df"
      ],
      "metadata": {
        "id": "lPXj_j6KTugj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 5 - XGBoost"
      ],
      "metadata": {
        "id": "IHYN-A0zT_JJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 4 Implementation\n",
        "xgb = XGBClassifier(n_estimators=100,max_depth=12,min_samples_leaf=20,min_samples_split=30)\n",
        "\n",
        "# Fit the Algorithm\n",
        "xgb.fit(x_train,y_train)"
      ],
      "metadata": {
        "id": "1ScTXVR_UGYC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "LQKaWu0AWpYE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "xgboost_eval = model_evaluation('XGBoost', xgb, x_train, y_train, x_test, y_test)\n",
        "xgboost_eval"
      ],
      "metadata": {
        "id": "Qtgz1wvdWy9l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#adding result to final list\n",
        "add_dict_to_final_df(xgboost_eval)\n",
        "comp_df"
      ],
      "metadata": {
        "id": "7PU8ImYrW_lv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "Z-hykwinpx6N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "comp_df"
      ],
      "metadata": {
        "id": "f780cqPtXOJr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visiualization for f1_score\n",
        "sns.barplot(y=comp_df['Model_Name'], x = comp_df['Test_F1score'])"
      ],
      "metadata": {
        "id": "M6VJnKSNXeWw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visiualization for AUC\n",
        "sns.barplot(y=comp_df['Model_Name'], x = comp_df['Test_AUC'])"
      ],
      "metadata": {
        "id": "YV55uAJzXsY4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Train F1 score and test f1 score for KNN classifier with best parameter and XGBoost are the highest out of all the models."
      ],
      "metadata": {
        "id": "MzVzZC6opx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Which Evaluation metrics did you consider for a positive business impact and why?"
      ],
      "metadata": {
        "id": "h_CCil-SKHpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- F1 score and ROC AUC are two evaluation metrics that can be useful for email campaign effectiveness prediction, especially when the data is imbalanced.\n",
        "- Both F1 and ROC AUC are suitable for imbalanced classification because they are not affected by the class distribution. They can provide a better indication of the classifier's performance than accuracy, which can be misleading when the data is skewed."
      ],
      "metadata": {
        "id": "jHVz9hHDKFms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
      ],
      "metadata": {
        "id": "cBFFvTBNJzUa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "comp_df"
      ],
      "metadata": {
        "id": "VcyUnyVbaR8N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the metrics, XG Boost Classifier and KNN Classifier with best parameter works the best giving a train F1 score of 96% and 99% respectively and test F1 score of 86.17% and 86.12% respectively."
      ],
      "metadata": {
        "id": "6ksF5Q1LKTVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Explain the model which you have used and the feature importance using any model explainability tool?"
      ],
      "metadata": {
        "id": "HvGl1hHyA_VK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_smote_df  = pd.DataFrame(x_smote, columns = x_scaled_df.columns)\n",
        "x_smote_df"
      ],
      "metadata": {
        "id": "sNtXxNnWbB5p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_df = pd.DataFrame(x_train, columns = x_smote_df.columns)\n",
        "x_train_df.head()"
      ],
      "metadata": {
        "id": "q7lN16zHbEJ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Importance - XGBoost\n",
        "feature_imp_xgb = pd.DataFrame({\"Variable\": x_train_df.columns,\"Importance\": xgb.feature_importances_})\n",
        "feature_imp_xgb.sort_values(by=\"Importance\", ascending=False, inplace = True)\n",
        "sns.barplot(x=feature_imp_xgb['Importance'], y= feature_imp_xgb['Variable'])"
      ],
      "metadata": {
        "id": "lZTrolGYa4dI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Feature with highest importance is shown by the bar plot.\n",
        "- Email_Campaign_Type is most important feature followed by Total_Past_Communications for XGBoost Classifier model."
      ],
      "metadata": {
        "id": "YnvVTiIxBL-C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***8.*** ***Future Work (Optional)***"
      ],
      "metadata": {
        "id": "EyNgTHvd2WFk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Save the best performing ml model in a pickle file or joblib file format for deployment process.\n"
      ],
      "metadata": {
        "id": "KH5McJBi2d8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the File"
      ],
      "metadata": {
        "id": "bQIANRl32f4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Again Load the saved model file and try to predict unseen data for a sanity check.\n"
      ],
      "metadata": {
        "id": "iW_Lq9qf2h6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the File and predict unseen data."
      ],
      "metadata": {
        "id": "oEXk9ydD2nVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!***"
      ],
      "metadata": {
        "id": "-Kee-DAl2viO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **From EDA**\n",
        "  - The percentage ratio of ignored, read and acknowledged emails are almost same for all the customer location. Customer Location does not exclusively influence the Email_Status. Both EDA and Chi-square hypothesis test showed the same result. So we should not consider location as a factor for people ignoring reading or acknowledging the emails.\n",
        "  - If campaign type is 1, then there 66% chances of emails being read and 23% chances of emails being acknowledged.\n",
        "  - Time_Email_Sent_category has no signifiacnt effect on Email_Status.\n",
        "  - Analyzing total past communications by performing EDA and one way ANOVA test, it is evident that the more the number of previous emails, the more it leads to read and acknowledged emails. This is just about making connection with the customers.\n",
        "  - The more the words in an email, the more tendency it has to get ignored. Too lengthy emails are getting ignored.\n",
        "\n",
        "- **Modeling**\n",
        "  - Based on the metrics, XG Boost Classifier and KNN Classifier with best parameter works the best, giving a train F1 score of 96% and 99% respectively and test F1 score of 86.17% and 86.12% respectively."
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}